---
title: "IODS Final Assignment"
author: "Maika"
date: "28 helmikuuta 2017"
output: 
  html_document:
    theme: readable
    highlight: tango
    toc: true
    toc_depth: 2
    toc_floath: true
    fig_caption: true
    fig_width: 6
    fig_height: 5
    code_folding: hide
  
---


#1 Introduction to open data science
##1.1 What have we learned?

This is a progress of a Bachelor level historian developing her skills with statistics with r-software. I have statistics as a minor and just started with Rm programmin language. My message to all of you is: If I can do this, so can you. I'm not saying it's easy, but I'm saying it's possible.

This course has been an introductory course to R-software using R-studio, Github and DataCamp. Through these weeks we have lerned to use R.markdown files and how to push changes with github from r.mrakdown to a html web page. We have also learned different data wrangling and analysing techiques briefly with data camp: [link](https://www.datacamp.com/)

What I've done so far can be seen in my course diary: [link](https://macabset.github.io/IODS-project/). We have had weekly assignments regarding a different data analysing method each week.

##1.2 What lies ahead of us
This is the final assignment for the course introduction to open data science. In thisasignment we create our own web pages from the scrach.(Oh, yes, you're reading it.)

In my github repository everyone can see the r-markdown codes for this web page. Basically it means, that if you have Rstudio and github username, you can copy the text and code from my github file, so YOU can make your own web page, too. How cool is that! Link to my Github repository is as promised: [link](https://github.com/macabset/IODS-final)

If you keep up with me (and I recommend that you will), you will learn how real life data is wrangled so that classes and groups from the data can be calculated and visualized. I'll do my best to explain every step adequately.

#2 Data: human


I'm going to use my human data from previous excercises. The dataset originates from United Nations Development Programme, and you can read more about it from here: [link](http://hdr.undp.org/en/content/human-development-index-hdi). 

I find this data the most interesting one we've used, since it's actual data that describes the wellbeing of nations in a very multilinear way. In stead of just using Gross National Product or Index as an explaining variable, we can take inequality or education levels as explanatory variables when explaining the wellbeing of a state. This way we do not compare nations simply based on their wealth but based on their human capacity. 

##2.1 Variables

I have created a subset called "human" with 9 variables and 155 observations. Variables modified from original dataset are Country, Edu2FM, LabFM and GNI. For further information about modifications made, you can go and check my github repository: [link](https://github.com/macabset/IODS-project/blob/master/data/create_human.R)

The data wrangling done here is strongly based on the original ch4 workout. In addition I have added variable HDI. I hope these additions will provide more of an backround knowledge to the evaluations of the connections. Further I will wrangle the data for the analysis.

Underneath are the names of the 10 variables and their description.

Country: used as rownames, regions not included
Edu2FM: ratio of females to males in at least secondary education
LabFM: ratio of female labour force to male labour force
Ed.exp: Expected years of education
Life.exp: Life expectancy at birth
GNI: Gross National Income per capita
Mot.mor: Maternal mortality ratio
Adol.birth: Adolescent birth rate
Adol.birth: Percentage of female representatives in parliament
HDI: human development index. Combination of education, life expectation and GNI.

In addition I have excluded missing values from our data set by removing them.

```{r}
#Packages we need in this workout
library(GGally)
library(dplyr)
library(corrplot)
library(FactoMineR)
library(ggplot2)
library(tidyr)
library(MASS)
```


```{r}
getwd()
human2 <- read.csv("data/human2.csv", sep=",", header = TRUE, row.names = 1)

str(human2)
dim(human2)
complete.cases(human2)
head(human2)
```

##Picturing the data

Let's do some corraltion matrises and plots to visualize them in order to notice the connection between variables.

```{r}
cor_human<-cor(human2) %>% round(digits=2)
cor_human
```

PUT TITLE IN THE PLOT: "Correlation between variables in human data"
```{r}
corrplot(cor_human,  main = "Correlation between variables in human data", method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex=0.6)
```
HDI has the highest correlations of all, but that is expected since it is a combination variable of many of the variables correlated to. This only shows, that HDI works as it's is supposed tO; it is able to collect long and healthy life and long education to it. It also reveals that not taking care of mothers influences to general human development negatively. 

More precisely, motherr' high mortality rate influences to life expectancy in general. Not as strongly, but strongly enough(-0.74) when mothers' die, the expected years of education lower, too. When taking a sub group of adolescent mothers, the interpretation is similar.

#3 Method: classification
Our data conserns broad view on human capcity and in my opinion, education is one of the best ways to increase human capacity. If we want to use our potential human capasity fully, we need to find out what are the structures that determine level of education. It is in the hands of politicians to determine what is the best level of education but it is the work of science to find out what are the reasons why some people have certain level of education.

Because I'm interested in levels of education, I believe classification method is the best analysing tool for that. I can divide the levels of education to groups and find out what variables determine which group. I don't aim to solve fully what are the reasons for such and such education level, but with our data we can use Linear Discriminant Analysis (LDA) to find out what are the variables that determine the groups of education. 

##Wrangling Human

But first we need to wrangle the data in order to make analysing with LDA possible. Let's find out what we need to do by looking the summary of the data.

```{r}
summary(human2)
```
We have all sorts of values in our variables from under a 1 or from 1 to 1100. In classification method, we're interested in the distances of the points in the data. In order to make these distances comparable, we need to scale the data.

### scaling human

```{r}
# center and standardize variables
human_scaled <- scale(human2)

# summaries of the scaled variables
summary(human_scaled)

# class of the human_scaled object
class(human_scaled)

#change the object to data frame
human_scaled <- as.data.frame(human_scaled)
class(human_scaled)
```
Now we have values only between -5 to 5. It is also transformed back to dataframe, so further analysis can be made.

###Creating levels of education
Now all we need is the target variable from the expected level of education. What we need is to divide our expected level of education to 4 class based on expected years of education.

*Creating a factor variable*

```{r}

# save the scaled Edu.exp as scaled_eduexp
scaled_eduexp <- human_scaled$Edu.exp

# summary of the scaled_eduexp
summary(scaled_eduexp)

# create a quantile vector of eduexp and print it
bins <- quantile(scaled_eduexp)
bins

# create a new categorical variable 'eduexp'
eduexp <- cut(scaled_eduexp, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))

# look at the table of the new factor
table(eduexp)

# remove original Edu.exp from the dataset
human_scaled <- dplyr::select(human_scaled, -Edu.exp)

# add the new categorical value to scaled data
human_scaled <- data.frame(human_scaled, eduexp)
str(human_scaled)
```
Now we have a new categorical variable eduexp instead of continuous Edu.exp in our scaled data set. It has levels low, med_low, med_high and high based on how the years are divided quantiles in our real data. The top 25% belongs to high education and bottom 25% to low class.

###Test set and train set

In order to divide our education level to groups in the original data we need a training test to create the 4 groups. We also need a test set to find out how well our model actually predicts the wanted groups in the data. Our model is created by train set and tested with test set.

We'll divide the whole data so, that randomly selected 80% of the data is used for the training and rest 20% for testing. We also need to exclude and save the original observations from expected level of education. Since that is what we want to predict, it cannot be in the testing set.


```{r}
# number of rows in the human dataset 
n <- nrow(human_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- human_scaled[ind,]

# create test set 
test <- human_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test$eduexp
summary(correct_classes)

# remove the eduexp variable from test data
test <- dplyr::select(test, -eduexp)
```

##LDA
Now we're ready to use the Linear Discriminant Analysis (LDA) in order to separate the data to groups. We will use train set to find those variables that best separate our target variable and test set to check how well our model predicts the classes.

In our LDA we have expected years of education as a target variable against all other variables. Here we obviously use our train set to create the model. Now we're ready to run the LDA, and it will create a model to predict expected years of education using all other variables.

*Model 1*
```{r}
lda.fit <- lda(formula= eduexp ~ ., data = train)

# print the lda.fit object
lda.fit

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$eduexp)

# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch=classes)
lda.arrows(lda.fit, myscale = 1)
#another plot with arrows showing
plot(lda.fit, dimen=2, cex = c(0.1))
lda.arrows(lda.fit, myscale = 2)
```
Our plot for the LDA is actually also a dimensionally reducted way of picturing the results. I have created two plots, first one to emphasize how well the groups are separated by giving each grpup a different colour and second plot to emphasize thevariables as arrows and their relationship to LD1 and LD2 and each other. The longer the arrow and narrower the angle between axis and an arrow, the stronger the connection between LD components and variables. The more separated groups the better the model.

Expected years of education have been predicted as levels by the LDA model and shown as a plot above. It shows the groups low to high in different colours and arrows as original variables that determine the groups. In our plot "1" we can see that the high end and the low end are best separated. In our plot "2" we can notice that HDI has the biggest connection to LD1 and so captures the largest variance when dividing groups based on expected years of education. Mother's mortality rate is the second strongest explanatory variable and strongly connected to LD2.

But since HDI is a combination variable based on already existing variables, I want to test what can be seen without it. That is why I'll exclude it here, so it won't cloud the interpretation of the results. So here we will do just as before but just without the HDI.

*Datawithout HDI*

```{r}
human_scaled2 <-human_scaled
human_scaled2 <- dplyr::select(human_scaled2, -HDI)
```
*TEst and training set without HDI*

```{r}
# number of rows in the human dataset 
n2 <- nrow(human_scaled2)

# choose randomly 80% of the rows
ind2 <- sample(n2,  size = n * 0.8)

# create train set
train2 <- human_scaled2[ind2,]

# create test set 
test2 <- human_scaled2[-ind2,]

# save the correct classes from test data
correct_classes2 <- test2$eduexp
summary(correct_classes2)

# remove the eduexp variable from test data
test2 <- dplyr::select(test2, -eduexp)
```

*Model 2, whithout HDI*
```{r}
lda.fit2 <- lda(formula= eduexp ~ ., data = train2)

# print the lda.fit object
lda.fit2

# the function for lda biplot arrows
lda.arrows2 <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes2 <- as.numeric(train2$eduexp)

# plot the lda results
plot(lda.fit2, dimen = 2, col=classes2, pch=classes2)
lda.arrows2(lda.fit2, myscale = 1)
lda.arrows(lda.fit, myscale = 1)
#another plot with arrows showing
plot(lda.fit2, dimen=2, cex = c(0.1))
lda.arrows(lda.fit2, myscale = 2)
```

As we can see in picture "1", without HDI our groups are a bit more mixed up, especially in med low and med high levels of education. In picture "2", we notice that mothers' moratality seems to be in great value, capturing second most variance from the data and determining how to group. When comparing to model one, we see that mean years of education is only one even closely related to LD1. That means that HDI in the first model was mainly based on years of education. That isn't very eluminating result that mean years of education predictws expecrted years of education.

What is more visible in the second model is the negative correlation between mother's mortality and education ratio from women to men. The higher the mother's mortality rate, the less women get to over second level education. 

*Model 2 in 3D*
```{r}
model_predictors <- dplyr::select(train2, -eduexp)
# check the dimensions
dim(model_predictors)
dim(lda.fit2$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit2$scaling
matrix_product <- as.data.frame(matrix_product)
library(plotly)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color=train2$eduexp)
```

##Predicting power of the models
We have interpreted the results but are the results valid? This is the point where we need our test set to test how well our models predict the data.

*Model 1*
```{r}
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```

*Model 2*
```{r}
# predict classes with test data
lda.pred2 <- predict(lda.fit2, newdata = test2)

# cross tabulate the results
table(correct = correct_classes2, predicted = lda.pred2$class)
```

The model1 with HDI predicts better, but in this version we have some variables in a way twice. That's why I believe that the second model is more interesting, as we can see more detailed results.

Also, even in the second case, our results are quite good in the low and high end. It seems, that same variables explain both med low and med high education levels and so cannot be separated as well. 

#clustering and LDA

I was also interested if our classification with expected years of education was reasonable. That's why I desided to test clustering method instead of classification as addition to our interpretation.

Clustering is an unsupervised method to divide our data to groups withour knowing the classes before hand. In this exercise we will use k-means, which is one of the most used method to do this.

But first, we need to scale our data again in order to calculate distances between observations properly. We will do that with data without HDI, since we discoverred that it's more describing data.

```{r}
summary(human_scaled2)
class(human_scaled2)
human_scaled2<- as.data.frame(human_scaled2)
```
*k-means*

Because clustering (with kmeans) is an unsupervised method, we do not know the optimal number of clusters beforehand. that's why we use euclidean distances to find out the optimal number of clusters. That's when in plot "x" the line drops rapidly. In this case, it's 2 clusters.
```{r}
dist_eu <- dist(human_scaled2)

# look at the summary of the distances
summary(dist_eu)
```

```{r}
library(ggplot2); library(GGally)
set.seed(123)

# euclidean distance matrix

# determine the number of clusters
k_max <- 10

# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})

# visualize the results
plot(1:k_max, twcss, type='b')
```

Now let's do kmeans clustering with 2 centers.

```{r}
# k-means clustering
km <-kmeans(dist_eu, centers = 2)

human_scaled2$km <- as.factor(km$cluster)

# plot the Boston dataset with clusters
ggpairs(human_scaled2, ggplot2::aes(colour=km))
```
If we compare these clusters to previous classification, we find out that expected years of education are strongly correlated to HDI (0.9) as in classification, even higher thatn to mean years of education (0.8). It is also corralted to both mother's mortality and adolescent births (0.7) as in classification method.

Although our optimal amount of clusters was 2, I will test it with the same amount of clusters as was in our classification. Then I will perform LDA with 4 clusters and clusters as target variable. Then I will compare the results of the LDA with classification method.

*LDA with k-means*

```{r}
# k-means again
set.seed(123)
km2 <- kmeans(dist_eu, centers = 4)

# LDA with using the k-means clusters as target classes
human_scaled2$cl <- km2$cluster
lda.fit2 <- lda(cl ~ ., data = human_scaled2)
plot(lda.fit2, col=as.numeric(human_scaled2$cl), dimen=2)
lda.arrows(lda.fit2, myscale = 2, col = "#666666")
```

In our LDA model 3 we have a lot of similarities to models 1 and 2 with classification method. Mothers' mortality is lamost fully correlated to expected years of education. Mother's mortality is again almost exactly lined with LD2 in collects most of the variation with the data. Also mother's mortality is negatively correalted to ratio of women to men in higher education.

AS was in our classification method, mothers mortality and HDI are the strongest 

Perform k-means on the original Boston data with some reasonable number of clusters (> 2). Remember to standardize the dataset. Then perform LDA using the clusters as target classes. Include all the variables in the Boston data in the LDA model. Visualize the results with a biplot (include arrows representing the relationships of the original variables to the LDA solution). Interpret the results. Which variables are the most influencial linear separators for the clusters? (2 points to compensate any loss of points from previous exercises)

Super-Bonus: Run the code below for the (scaled) train data that you used to fit the LDA. The code creates a matrix product, which is a projection of the data points.



Next, install and access the Plotly package. Create a 3D plot (Cool!) of the columns of the matrix product by typing the code below.


#Extra

#Conclusion
Since the mothers' mortality has a lot stronger connection to LD2 thatn edu2FM, I'd say that it is the wellbeing of mothers' that count in estimating both expected years of education and the ratio from women to men in education level instead the other way around.



